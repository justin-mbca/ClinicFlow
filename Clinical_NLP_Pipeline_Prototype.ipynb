{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e473b1f",
   "metadata": {},
   "source": [
    "# Clinical Text De-identification & Insight Extraction Pipeline (Prototype)\n",
    "\n",
    "This notebook demonstrates a prototype workflow for de-identifying clinical text and extracting medical entities using both Azure Cognitive Services and open-source NLP models. It includes documentation and resume bullet points for portfolio submission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4df293a",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import all necessary Python libraries required for the workflow prototype, such as pandas, numpy, and any workflow-related packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5af7026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "from typing import List, Dict\n",
    "\n",
    "# Mock imports for Azure and open-source NLP (for prototype)\n",
    "# from azure.ai.textanalytics import TextAnalyticsClient\n",
    "# import spacy\n",
    "# from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6892df2",
   "metadata": {},
   "source": [
    "## 2. Define Workflow Prototype Functions\n",
    "\n",
    "Create Python functions that represent each step of the workflow. Use mock data and placeholder logic to simulate the workflow steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d627854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Preprocess clinical text (de-identification)\n",
    "def clean_clinical_text(text: str) -> str:\n",
    "    \"\"\"Remove PHI using regex and mask with placeholders.\"\"\"\n",
    "    text = re.sub(r\"\\\\b\\\\d{1,2}/\\\\d{1,2}/\\\\d{2,4}\\\\b\", \"[DATE]\", text)\n",
    "    text = re.sub(r\"MRN:\\\\d+\", \"[ID]\", text)\n",
    "    text = re.sub(r\"\\\\b\\\\d{3}-\\\\d{3}-\\\\d{4}\\\\b\", \"[PHONE]\", text)\n",
    "    text = re.sub(r\"\\\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "# Step 2: Mock Azure Cognitive Services entity extraction\n",
    "def azure_extract_entities(texts: List[str]) -> List[Dict]:\n",
    "    \"\"\"Simulate Azure Health entity extraction.\"\"\"\n",
    "    # Mock output\n",
    "    entities = []\n",
    "    for text in texts:\n",
    "        entities.append({\n",
    "            'text': 'aspirin',\n",
    "            'category': 'MedicationName',\n",
    "            'confidence_score': round(random.uniform(0.8, 1.0), 2),\n",
    "            'offset': text.find('aspirin')\n",
    "        })\n",
    "    return entities\n",
    "\n",
    "# Step 3: Mock open-source NER entity extraction\n",
    "def open_source_extract_entities(texts: List[str]) -> List[Dict]:\n",
    "    \"\"\"Simulate open-source NER extraction.\"\"\"\n",
    "    entities = []\n",
    "    for text in texts:\n",
    "        entities.append({\n",
    "            'text': 'Type 2 Diabetes',\n",
    "            'category': 'Diagnosis',\n",
    "            'confidence_score': round(random.uniform(0.7, 0.95), 2),\n",
    "            'offset': text.find('Diabetes')\n",
    "        })\n",
    "    return entities\n",
    "\n",
    "# Step 4: Simulate saving to Azure SQL DB\n",
    "def save_to_sql_db(entities: List[Dict], source: str):\n",
    "    print(f\"Saving {len(entities)} entities from {source} to Azure SQL DB (simulated)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a63f82",
   "metadata": {},
   "source": [
    "## 3. Simulate Workflow Execution\n",
    "\n",
    "Run the workflow prototype using the defined functions. Show sample input and output for each step to demonstrate the workflow logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae49952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample clinical notes\n",
    "data = [\n",
    "    \"Patient MRN:12345 was prescribed aspirin on 12/01/2023. Diagnosed with Type 2 Diabetes. Call 555-123-4567.\",\n",
    "    \"MRN:67890, admitted 01/15/2024, hypertension noted.\"\n",
    "]\n",
    "\n",
    "# Step 1: Preprocess\n",
    "cleaned = [clean_clinical_text(t) for t in data]\n",
    "print(\"Cleaned Text:\", cleaned)\n",
    "\n",
    "# Step 2: Azure extraction (mock)\n",
    "az_entities = azure_extract_entities(cleaned)\n",
    "print(\"Azure Entities:\", az_entities)\n",
    "\n",
    "# Step 3: Open-source extraction (mock)\n",
    "os_entities = open_source_extract_entities(cleaned)\n",
    "print(\"Open-Source Entities:\", os_entities)\n",
    "\n",
    "# Step 4: Save to SQL DB (simulated)\n",
    "save_to_sql_db(az_entities, source=\"Azure Cognitive Services\")\n",
    "save_to_sql_db(os_entities, source=\"Open-Source NLP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6b0a3c",
   "metadata": {},
   "source": [
    "## 4. Workflow Documentation\n",
    "\n",
    "### Step 1: Preprocessing\n",
    "- **Purpose:** Remove/mask PHI (dates, IDs, phone numbers) from clinical text.\n",
    "- **Input:** Raw clinical notes (string)\n",
    "- **Output:** Cleaned, de-identified text\n",
    "\n",
    "### Step 2: Entity Extraction (Azure)\n",
    "- **Purpose:** Extract medical entities using Azure Cognitive Services for Health (simulated here)\n",
    "- **Input:** Cleaned text\n",
    "- **Output:** List of entities with category, confidence, offset\n",
    "\n",
    "### Step 3: Entity Extraction (Open-Source)\n",
    "- **Purpose:** Extract medical entities using open-source models (spaCy/Hugging Face, simulated here)\n",
    "- **Input:** Cleaned text\n",
    "- **Output:** List of entities with category, confidence, offset\n",
    "\n",
    "### Step 4: Save Results\n",
    "- **Purpose:** Store structured results in Azure SQL Database (simulated)\n",
    "- **Input:** List of entities\n",
    "- **Output:** Confirmation of save\n",
    "\n",
    "---\n",
    "\n",
    "#### High-Level Workflow Diagram (Pseudocode)\n",
    "\n",
    "```\n",
    "Raw Clinical Notes\n",
    "   |\\\n",
    "   |  [Preprocess: clean_clinical_text]\n",
    "   |/\n",
    "Cleaned Text\n",
    "   |\\\n",
    "   |  [Azure Entity Extraction]   [Open-Source Entity Extraction]\n",
    "   |/                             |\\\n",
    "Entities (Azure)           Entities (Open-Source)\n",
    "   |\\                         |\\\n",
    "   |  [Save to SQL DB]        |  [Save to SQL DB]\n",
    "   |/                         |/\n",
    "Structured Results in Azure SQL DB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01366b46",
   "metadata": {},
   "source": [
    "## 5. Resume Bullet Points for Portfolio Project\n",
    "\n",
    "- Designed and prototyped a clinical NLP pipeline for de-identification and medical entity extraction using both Azure Cognitive Services and open-source models.\n",
    "- Implemented secure, modular workflow steps for PHI masking, entity extraction, and structured data storage.\n",
    "- Demonstrated parallel data flows to compare cloud-native and open-source NLP approaches for healthcare text.\n",
    "- Automated PHI masking and simulated SNOMED CT mapping, showcasing advanced healthcare data engineering skills.\n",
    "- Documented the workflow and results for clear communication and portfolio presentation."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
